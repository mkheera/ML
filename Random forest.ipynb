{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest using kaggle dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['train.csv', 'test.csv', 'gender_submission.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "data= pd.read_csv(\"../input/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 891 entries, 0 to 890\n",
    "Data columns (total 12 columns):\n",
    "PassengerId    891 non-null int64\n",
    "Survived       891 non-null int64\n",
    "Pclass         891 non-null int64\n",
    "Name           891 non-null object\n",
    "Sex            891 non-null object\n",
    "Age            714 non-null float64\n",
    "SibSp          891 non-null int64\n",
    "Parch          891 non-null int64\n",
    "Ticket         891 non-null object\n",
    "Fare           891 non-null float64\n",
    "Cabin          204 non-null object\n",
    "Embarked       889 non-null object\n",
    "dtypes: float64(2), int64(5), object(5)\n",
    "memory usage: 83.6+ KB\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no of survived people in each class\n",
    "survived_class = data[data['Survived']==1]['Pclass'].value_counts()\n",
    "didntsurvive_class = data[data['Survived']==0]['Pclass'].value_counts()\n",
    "df_class = pd.DataFrame([survived_class,didntsurvive_class])\n",
    "df_class.index = ['Survived','Died']\n",
    "display(df_class)\n",
    "data['Died'] = 1 - data['Survived']\n",
    "data.groupby('Pclass').agg('mean')[['Survived', 'Died']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no of survived people in each sex\n",
    "survived_sex = data[data['Survived']==1]['Sex'].value_counts()\n",
    "didntsurvive_sex = data[data['Survived']==0]['Sex'].value_counts()\n",
    "df_sex = pd.DataFrame([survived_sex,didntsurvive_sex])\n",
    "df_sex.index = ['Survived','Died']\n",
    "\n",
    "#print(data[['Sex','Survived']].groupby(['Sex'],as_index=False).mean())\n",
    "data['Died'] = 1 - data['Survived']\n",
    "data.groupby('Sex').agg('mean')[['Survived', 'Died']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combining two features into Familysize\n",
    "for lines in data:\n",
    "    data['Familysize']=data['SibSp']+data['Parch']+ 1\n",
    "data.groupby('Familysize').agg('mean')[['Survived', 'Died']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Familysize\tSurvived\tDied\n",
    "1\t0.303538\t0.696462\n",
    "2\t0.552795\t0.447205\n",
    "3\t0.578431\t0.421569\n",
    "4\t0.724138\t0.275862\n",
    "5\t0.200000\t0.800000\n",
    "6\t0.136364\t0.863636\n",
    "7\t0.333333\t0.666667\n",
    "8\t0.000000\t1.000000\n",
    "11\t0.000000\t1.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merging train data and test data for future feature engineering\n",
    "def get_combined_data():\n",
    "    # reading train data\n",
    "    train = pd.read_csv(\"../input/train.csv\")\n",
    "    \n",
    "    # reading test data\n",
    "    test = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "    # extracting and then removing the targets from the training data \n",
    "    targets = train.Survived\n",
    "    #train.drop(['Survived'], 1, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "    # we'll also remove the PassengerID since this is not an informative feature\n",
    "    combined = train.append(test)\n",
    "    combined.reset_index(inplace=True)\n",
    "    combined.drop(['index'],1,inplace=True)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = get_combined_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = combined.copy()                    \n",
    "y = data.Survived "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extracting title\n",
    "got= (X.Name.str.split(',').str[1]).str.strip()\n",
    "X.Name=pd.DataFrame(got).Name.str.split('.').str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding sex\n",
    "print ('Number of null values in Sex:', sum(X.Sex.isnull()))\n",
    "X.Sex.replace({ 'male':1, 'female':2}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#treating missing values in age and encoding\n",
    "print ('Number of null values in Age:', sum(X.Age.isnull()))\n",
    "X['Age']=X['Age'].fillna(X['Age'].mean())\n",
    "print ('Number of null values in Age:', sum(X.Age.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#treating missing values in embarked \n",
    "print ('Number of null values in Embarked:', sum(X.Embarked.isnull()))\n",
    "\n",
    "# fill the two values with one of the options (S, C or Q)\n",
    "for dat in X:\n",
    "    X['Embarked']=X['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#treating missing values in embarked \n",
    "print ('Number of null values in Embarked:', sum(X.Embarked.isnull()))\n",
    "\n",
    "# fill the two values with one of the options (S, C or Q)\n",
    "for dat in X:\n",
    "    X['Embarked']=X['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.groupby('Cabin').agg('mean')[['Survived']]\n",
    "Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cabin Survived\n",
    "0\t  0.299854\n",
    "1\t  0.666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for lines in X:\n",
    "    X['Familysize']=X['SibSp']+X['Parch']+ 1\n",
    "#data.groupby('Familysize').agg('mean')[['Survived', 'Died']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#survived rate based on Title    \n",
    "X[['Name','Survived']].groupby(['Name'],as_index=False).agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name\tSurvived\n",
    "0\tCapt\t0.000000\n",
    "1\tCol\t0.500000\n",
    "2\tDon\t0.000000\n",
    "3\tDona\tNaN\n",
    "4\tDr\t0.428571\n",
    "5\tJonkheer\t0.000000\n",
    "6\tLady\t1.000000\n",
    "7\tMajor\t0.500000\n",
    "8\tMaster\t0.575000\n",
    "9\tMiss\t0.697802\n",
    "10\tMlle\t1.000000\n",
    "11\tMme\t1.000000\n",
    "12\tMr\t0.156673\n",
    "13\tMrs\t0.792000\n",
    "14\tMs\t1.000000\n",
    "15\tRev\t0.000000\n",
    "16\tSir\t1.000000\n",
    "17\tthe Countess\t1.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding embarked\n",
    "X['Embarked']=X.Embarked.replace({'S':0,'C':1,'Q':2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mapping name\n",
    "X['Title']=X['Name'].replace('the Countess','Royal')\n",
    "X['Title']=X.Title.replace(['Lady','Countess','Capt','Col', 'Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'Royal')\n",
    "X['Title']=X['Title'].replace('Mlle','Miss')\n",
    "X['Title']=X['Title'].replace('Ms','Miss')\n",
    "X['Title']=X['Title'].replace('Mme','Mrs')\n",
    "X.Title.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array(['Mr', 'Mrs', 'Miss', 'Master', 'Royal'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding title\n",
    "X.head(5)\n",
    "#title_mapping={'Mr':1,'Mrs':2,'Master':3,'Miss':4,'Rare':5}\n",
    "#X['Title']=X['Title'].replace(title_mapping,inplace=True)\n",
    "X['Title']=X['Title'].replace({'Mr':1,'Mrs':2,'Master':3,'Miss':4,'Royal':5}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mapping Fare\n",
    "X.loc[X.Fare <= 7.91,'Fare']=0\n",
    "X.loc[(X.Fare > 7.91) & (X.Fare <= 14.454),'Fare']=1\n",
    "X.loc[(X.Fare > 14.454) & (X.Fare <= 31),'Fare']=2\n",
    "X.loc[X.Fare > 31,'Fare']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mapping Age\n",
    "\n",
    "X.loc[X.Age <= 16,'Age']=0\n",
    "X.loc[(X.Age > 16) & (X.Age <= 32),'Age']=1\n",
    "X.loc[(X.Age > 32) & (X.Age <= 48),'Age']=2\n",
    "X.loc[(X.Age > 48) & (X.Age <= 64),'Age']=3\n",
    "X.loc[X.Fare > 64,'Age']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.drop(['Ticket','Name','SibSp','PassengerId','Survived'],axis=1,inplace=True)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = X.iloc[:891]\n",
    "test = X.iloc[891:]\n",
    "targets = pd.read_csv('../input/train.csv', usecols=['Survived'])['Survived'].values\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(color_codes=True) #background grid\n",
    "#sns.pairplot(train) #relation betn each pair of columns.\n",
    "colormap=plt.cm.viridis\n",
    "plt.figure(figsize= (14,14))\n",
    "plt.title('Correlation of features',y=1.03,size =20)\n",
    "sns.heatmap(train.astype(float).corr(),linewidths=0.1,square=True,cmap=colormap,linecolor='black',annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Limit depth of tree to 3 levels\n",
    "from sklearn.tree import export_graphviz\n",
    "#import pydot\n",
    "rf_small = RandomForestClassifier(n_estimators=10, max_depth = 3)\n",
    "clf =rf_small.fit(train, targets)\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the tree as a png image\n",
    "#export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "#(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "#graph.write_png('small_tree.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "features['feature'] = train.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)\n",
    "features.plot(kind='barh', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xval = cross_val_score(clf, train, targets, cv = 5, scoring='accuracy')\n",
    "score=np.mean(xval)\n",
    "print ('CV score = {0}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV score = 0.8126021575388496"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "test.info()\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 418 entries, 891 to 1308\n",
    "Data columns (total 9 columns):\n",
    "Age           418 non-null float64\n",
    "Cabin         418 non-null int64\n",
    "Embarked      418 non-null int64\n",
    "Fare          418 non-null float64\n",
    "Parch         418 non-null int64\n",
    "Pclass        418 non-null int64\n",
    "Sex           418 non-null int64\n",
    "Familysize    418 non-null int64\n",
    "Title         418 non-null int64\n",
    "dtypes: float64(2), int64(7)\n",
    "memory usage: 29.5 KB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions and determine the error\n",
    "predictions = clf.predict(test).astype(int)\n",
    "df_output = pd.DataFrame()\n",
    "aux = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "df_output['PassengerId'] = aux['PassengerId']\n",
    "df_output['Survived'] = predictions\n",
    "\n",
    "df_output[['PassengerId','Survived']].to_csv(\"randomforest.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
